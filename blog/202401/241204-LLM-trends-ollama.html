<!DOCTYPE html><html><head>
      <title>AI开发者频道</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview .alert {
  padding: 15px;
  margin-bottom: 20px;
  border: 1px solid transparent;
  border-radius: 4px;
  display: block;
  width: auto;
}
.markdown-preview.markdown-preview .alert > p,
.markdown-preview.markdown-preview .alert > ul {
  margin-bottom: 0;
}
.markdown-preview.markdown-preview .alert-danger {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.markdown-preview.markdown-preview .alert-success {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.markdown-preview.markdown-preview .alert-info {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.markdown-preview.markdown-preview .alert-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<p><strong>目录索引</strong></p>
<div class="code-chunk" data-id="code-chunk-id-0" data-cmd="toc"><div class="input-div"><div class="code-chunk-btn-group"><div class="run-btn btn btn-xs btn-primary"><span>▶︎</span></div><div class="run-all-btn btn btn-xs btn-primary">all</div></div><div class="status">running...</div></div><div class="output-div"></div></div><ul>
<li><a href="#2024%E5%B9%B4llm%E8%BF%9B%E5%B1%95%E5%9B%9E%E9%A1%BE%E9%80%9A%E8%BF%87ollama%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97%E7%9C%8Bllm%E8%BF%9B%E5%B1%95">2024年LLM进展回顾，通过Ollama更新日志看LLM进展</a>
<ul>
<li><a href="#%E5%86%85%E5%AE%B9%E6%A6%82%E8%A6%81">内容概要</a></li>
<li><a href="#%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE-1-3%E6%9C%88">统计数据 1-3月</a></li>
<li><a href="#%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE-4-5%E6%9C%88">统计数据 4-5月</a></li>
<li><a href="#%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE-7-9%E6%9C%88">统计数据 7-9月</a></li>
<li><a href="#%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE-10-11%E6%9C%88-12%E6%9C%88%E5%86%85%E5%AE%B9%E5%BE%85%E8%A1%A5%E5%85%85">统计数据 10-11月 （12月内容待补充）</a></li>
</ul>
</li>
</ul>
<h2 id="2024年llm进展回顾通过ollama更新日志看llm进展">2024年LLM进展回顾，通过Ollama更新日志看LLM进展 </h2>
<h3 id="内容概要">内容概要 </h3>
<p>通过Ollama更新日志看2024年开源LLM发展状况</p>
<ul>
<li>Ollama更新日志（日志收集范围2024年1月-11月，对应版本号：v0.1.18-v0.4.7）</li>
<li>来源地址：<a href="https://github.com/ollama/ollama/releases">https://github.com/ollama/ollama/releases</a></li>
</ul>
<h3 id="统计数据-1-3月">统计数据 1-3月 </h3>
<table>
<thead>
<tr>
<th style="text-align:center">时间</th>
<th style="text-align:center">版本号</th>
<th>新加入模型</th>
<th>Ollama新功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Jan 6</td>
<td style="text-align:center">v0.1.18</td>
<td>TinyLlama(1.1B) <br> OpenHermes2(Mistral-based,7B) <br> WizardCoder(Code, 33B)<br> Dolphin Phi(Microsoft,uncensored, 2.7B)</td>
<td>注：支持GPUs with 4GB of memory or less</td>
</tr>
<tr>
<td style="text-align:center">Jan 10</td>
<td style="text-align:center">v0.1.19</td>
<td>LLaMa-Pro(Tencent, 8B)</td>
<td>增加了提高context size的设置</td>
</tr>
<tr>
<td style="text-align:center">Jan 11</td>
<td style="text-align:center">v0.1.20</td>
<td>MegaDolphin(120B) <br> OpenChat <br> Dolphin Mistral（DPO训练的模型）</td>
<td><font color="red">Multi-GPU support</font></td>
</tr>
<tr>
<td style="text-align:center">Jan 26</td>
<td style="text-align:center">v0.1.21</td>
<td>Qwen (Alibaba, 1.8B to 72B) <br> <font color="red">DuckDB-NSQL(text-to-sql)</font> <br> Stable Code (llama-based, 7B) <br>  Nous Hermes 2 Mixtral</td>
<td>Suppot more CPUs(CPUs without AVX)<br>  Support MESSAGE Modelfile to set vonversation history</td>
</tr>
<tr>
<td style="text-align:center">Jan 27</td>
<td style="text-align:center">v0.1.22</td>
<td>Stable LM 2 （1.6B）</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Feb 2</td>
<td style="text-align:center">v0.1.23</td>
<td><font color="red">Llava（视觉，7B，13B，34B）</font></td>
<td><font color="red">支持Vision视觉模型</font> <br>  <font color="red">新增支持更多英伟达GPU</font> <br> keep_alive 模型加载保持时间设置</td>
</tr>
<tr>
<td style="text-align:center">Feb 8</td>
<td style="text-align:center">v0.1.24</td>
<td>Qwen1.5（Alibaba，0.5B to 72B）</td>
<td>提供OpenAI兼容格式的API服务</td>
</tr>
<tr>
<td style="text-align:center">Feb 15</td>
<td style="text-align:center">v0.1.25</td>
<td></td>
<td><font color="red">支持Windows操作系统</font> <br> keep_alive -1 支持模型永久导入模式</td>
</tr>
<tr>
<td style="text-align:center">Feb 21</td>
<td style="text-align:center">v0.1.26</td>
<td></td>
<td><font color="red">支持embedding模型(bert, nomic-bert)</font></td>
</tr>
<tr>
<td style="text-align:center">Feb 23</td>
<td style="text-align:center">v0.1.27</td>
<td>Gemma （Google, 2B, 7B）</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Mar 2</td>
<td style="text-align:center">v0.1.28</td>
<td>StarCoder2 (3B, 7B, 15B) <br> DolphinCoder (Code, 15B) <br> llava 1.6 (视觉)</td>
<td>改进了视觉模型回答文本问题的能力 <br>  支持llava 1.6模型</td>
</tr>
<tr>
<td style="text-align:center">Mar 15</td>
<td style="text-align:center">v0.1.29</td>
<td></td>
<td><font color="red">开始支持AMD显卡</font> <br> 测试：Modelfile支持导入safetensors模型</td>
</tr>
<tr>
<td style="text-align:center">Mar 29</td>
<td style="text-align:center">v0.1.30</td>
<td>Command R <br>  <font color="red">mxbai-embed-large（embedding）</font></td>
<td><font color="red">支持 AMD MI300 and MI300X 加速器</font></td>
</tr>
</tbody>
</table>
<h3 id="统计数据-4-5月">统计数据 4-5月 </h3>
<table>
<thead>
<tr>
<th style="text-align:center">时间</th>
<th style="text-align:center">版本号</th>
<th>新加入模型</th>
<th>Ollama新功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Apr 5</td>
<td style="text-align:center">v0.1.31</td>
<td>Qwen 1.5(Alibaba, 32B) <br> StarlingLM Beta(7B) <br> DolphinCoder StarCoder 7B(Code, 7B) <br> StableLM 1.6 Chat</td>
<td><font color="red">正式声称支持embedding模型</font></td>
</tr>
<tr>
<td style="text-align:center">Apr 17</td>
<td style="text-align:center">v0.1.32</td>
<td>WizardLM 2 (微软，Mistral model-based，8x22B，7B) <br> Snowflake Arctic Embed(embedding) <br> <font color="red">Command R+ (For RAG)</font> <br>DBRX (132B) <br> Mixtral 8x22B</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">May 3</td>
<td style="text-align:center">v0.1.33</td>
<td>Llama 3 (Meta)  <br> Phi 3 Mini(Microsoft, 3.8B) <br> Moondream (视觉) <br> Llama 3 Gradient 1048K(1M context window) <br> Dolphin Llama 3 <br> Qwen 110B (Qwen系列第一个超过100B模型)</td>
<td><font color="red">测试功能：单模型同时多请求；多模型导入支持</font></td>
</tr>
<tr>
<td style="text-align:center">May 8</td>
<td style="text-align:center">v0.1.34</td>
<td>Llava Llama 3(视觉)<br> Llava Phi 3(视觉) <br> StarCoder2 15B InstructB(Code, 15B)<br> CodeGemma 1.1(Google) <br> StableLM2 12B （Stability AI） <br> Moondream 2 (视觉)</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">May 11</td>
<td style="text-align:center">v0.1.35</td>
<td><font color="red">Llama 3 ChatQA(NVIDIA, for QA and RAG)</font></td>
<td>支持create时对模型进行量化设置</td>
</tr>
<tr>
<td style="text-align:center">May 11</td>
<td style="text-align:center">v0.1.36</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">May 12</td>
<td style="text-align:center">v0.1.37</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">May 16</td>
<td style="text-align:center">v0.1.38</td>
<td>Falcon 2(TII, 11B) <br> Yi 1.5(零一万物，6B, 9B, 34B)</td>
<td>新命令支持：ollama ps（列出导入模型的信息）；clear（清楚历史对话记录）</td>
</tr>
<tr>
<td style="text-align:center">May 29</td>
<td style="text-align:center">v0.1.39</td>
<td>Cohere Aya 23(multilingual 23种语言) <br> Mistral 7B 0.3 （Mixtral，7B，<font color="red">支持function calling</font>） <br> Phi-3 Medium（微软，14B） <br> Phi-3 Mini 128K and Phi-3 Medium 128K <br> Granite code（by IBM）</td>
<td><font color="red">支持直接导入HF的llama3模型（safetensor格式）</font></td>
</tr>
<tr>
<td style="text-align:center">Jun 1</td>
<td style="text-align:center">v0.1.40</td>
<td>Codestral(Mistral AI, Code) <br> Granite Code（IBM, 3B, 8B） <br> <font color="red">Deepseek V2（MoE）</font></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jun 2</td>
<td style="text-align:center">v0.1.41</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jun 8</td>
<td style="text-align:center">v0.1.42</td>
<td>Qwen 2 系列(Alibaba)</td>
<td>支持Electron 和 Tauri 的本地开发访问</td>
</tr>
<tr>
<td style="text-align:center">Jun 12</td>
<td style="text-align:center">v0.1.43</td>
<td></td>
<td>更新了import.md的模型导入说明</td>
</tr>
<tr>
<td style="text-align:center">Jun 14</td>
<td style="text-align:center">v0.1.44</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jun 21</td>
<td style="text-align:center">v0.1.45</td>
<td>DeepSeek-Coder-V2 (16B, 236B MoE模型)</td>
<td>增加了ollama show的信息（context length， embedding length etc）</td>
</tr>
<tr>
<td style="text-align:center">Jun 25</td>
<td style="text-align:center">v0.1.46</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jun 27</td>
<td style="text-align:center">v0.1.47</td>
<td>Gemma 2 models (Google，9B and 27B)</td>
<td>支持Gemma 2 models (9B and 27B)</td>
</tr>
<tr>
<td style="text-align:center">Jun 29</td>
<td style="text-align:center">v0.1.48</td>
<td></td>
<td>fix与Gemma2相关的问题</td>
</tr>
</tbody>
</table>
<h3 id="统计数据-7-9月">统计数据 7-9月 </h3>
<table>
<thead>
<tr>
<th style="text-align:center">时间</th>
<th style="text-align:center">版本号</th>
<th>新加入模型</th>
<th>Ollama新功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Jul 9</td>
<td style="text-align:center">v0.2.0</td>
<td><font color="red">GLM-4</font> <br> CodeGeeX4 <br> Gemma 2</td>
<td><font color="red">支持单模型并行访问 <br> 支持同时启动多模型</font></td>
</tr>
<tr>
<td style="text-align:center">Jul 9</td>
<td style="text-align:center">v0.2.1</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 13</td>
<td style="text-align:center">v0.2.2</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 13</td>
<td style="text-align:center">v0.2.3</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 14</td>
<td style="text-align:center">v0.2.4</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 14</td>
<td style="text-align:center">v0.2.5</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 19</td>
<td style="text-align:center">v0.2.6</td>
<td>Mathstral(Mistral AI, 7B)</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 19</td>
<td style="text-align:center">v0.2.7</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 23</td>
<td style="text-align:center">v0.2.8</td>
<td>Mistral Nemo(Mistral AI and NVIDIA, 12B, 128K context) <br> NuExtract (Phi-3-based, 3.8B)</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Jul 26</td>
<td style="text-align:center">v0.3.0</td>
<td>Llama 3.1(Meta, 8B, 70B, 405B, tool calling) <br> Mistral Large 2(Mistral AI, 123B, 128K context, code, tool) <br> Firefunction v2 (llama3-based, function calling) <br> Llama-3-Groq-Tool-Use (tool calling)</td>
<td><font color="red">支持tool calling （Functions and APIs， Web browsing， Code Interpreter）</font></td>
</tr>
<tr>
<td style="text-align:center">Jul 31</td>
<td style="text-align:center">v0.3.1</td>
<td>Gemma 2 2B(google，2B)</td>
<td>support min_p 参数</td>
</tr>
<tr>
<td style="text-align:center">Aug 1</td>
<td style="text-align:center">v0.3.2</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Aug 2</td>
<td style="text-align:center">v0.3.3</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Aug 7</td>
<td style="text-align:center">v0.3.4</td>
<td><font color="red">BGE-M3(BAAI, embedding) <br> BGE-Large (embedding) <br> Paraphrase-Multilingual(embedding, 50 languages)</font></td>
<td>new embedding API with batch support</td>
</tr>
<tr>
<td style="text-align:center">Aug 12</td>
<td style="text-align:center">v0.3.5</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Aug 14</td>
<td style="text-align:center">v0.3.6</td>
<td></td>
<td>support Create Phi-3 models from Safetensors</td>
</tr>
<tr>
<td style="text-align:center">Aug 27</td>
<td style="text-align:center">v0.3.7</td>
<td>Hermes 3(tool calling) <br> Phi 3.5 (微软，3.8B)  <br> SmolLM （135M, 360M, 1.7B）</td>
<td>CUDA12 support</td>
</tr>
<tr>
<td style="text-align:center">Aug 28</td>
<td style="text-align:center">v0.3.8</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Sep 1</td>
<td style="text-align:center">v0.3.9</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Sep 7</td>
<td style="text-align:center">v0.3.10</td>
<td>MiniCPM-V (multi-modal) <br> Yi-Coder(10B) <br> DeepSeek-V2.5</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Sep 18</td>
<td style="text-align:center">v0.3.11</td>
<td>Solar-Pro-Preview(22B) <br> Qwen 2.5 (18T train data, 128K context) <br>Bespoke-Minicheck <br> <font color="red">Mistral-Small(22B for translation and summarization etc) <br> Reader-LM (0.5B, 1.5B, convert HTML content to Markdown)</font></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Sep 23</td>
<td style="text-align:center">v0.3.12</td>
<td>Llama 3.2 (Meta, 1B, 3B) <br> Qwen 2.5 Coder (Code generation, code reasoning, code fixing)</td>
<td>supports ARM Windows machines</td>
</tr>
</tbody>
</table>
<h3 id="统计数据-10-11月-12月内容待补充">统计数据 10-11月 （12月内容待补充） </h3>
<table>
<thead>
<tr>
<th style="text-align:center">时间</th>
<th style="text-align:center">版本号</th>
<th>新加入模型</th>
<th>Ollama新功能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Oct 12</td>
<td style="text-align:center">v0.3.13</td>
<td><font color="red">Safty: Llama Guard 3(Meta) <br> Safty: ShieldGemma(Google)</font></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Oct 18</td>
<td style="text-align:center">v0.3.14</td>
<td>Granite 3 MoE(IBM, 1B, 3B) <br> Granite 3 Dense(IBM, 2B, 8B, Code, RAG, tool)</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Oct 21</td>
<td style="text-align:center">v0.4.0</td>
<td>Llama 3.2 Vision(Meta, 11B, 90B)</td>
<td>Support Llama3.2 Vision <br> <font color="red">支持直接导入Safetensors模型（不需要Modelfile）</font></td>
</tr>
<tr>
<td style="text-align:center">Nov 8</td>
<td style="text-align:center">v0.4.1</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Nov 15</td>
<td style="text-align:center">v0.4.2</td>
<td>Qwen 2.5 Coder (Alibaba, 0.5B, 1.5B, 3B, 7B, 14B and 32B) <br> OpenCoder(1.5B, 8B) <br> Athene V2 (Math, 72B)</td>
<td>supports NVIDIA Jetson</td>
</tr>
<tr>
<td style="text-align:center">Nov 21</td>
<td style="text-align:center">v0.4.3</td>
<td>Tülu 3 <br>  Mistral Large</td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Nov 23</td>
<td style="text-align:center">v0.4.4</td>
<td><font color="red">Marco-o1 (Alibaba, 7B, reasoning model) </font></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Nov 25</td>
<td style="text-align:center">v0.4.5</td>
<td></td>
<td><font color="red">Ollama Python Library 升级(Python functions can now be provided as tools to models) </font></td>
</tr>
<tr>
<td style="text-align:center">Nov 27</td>
<td style="text-align:center">v0.4.6</td>
<td><font color="red">QwQ(Alibaba Qwen team, 32B, advancing AI reasoning)</font></td>
<td></td>
</tr>
<tr>
<td style="text-align:center">Nov 30</td>
<td style="text-align:center">v0.4.7</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>