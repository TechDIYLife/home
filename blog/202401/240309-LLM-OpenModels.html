<!DOCTYPE html><html><head>
      <title>LLM开源模型调查</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<p><font size="6px" style="line-height: 1.3;"><b>LLM开源模型调查（2024年3月版）</b></font></p>
<p><strong>目录索引</strong></p>
<div class="code-chunk" data-id="code-chunk-id-0" data-cmd="toc"><div class="input-div"><div class="code-chunk-btn-group"><div class="run-btn btn btn-xs btn-primary"><span>▶︎</span></div><div class="run-all-btn btn btn-xs btn-primary">all</div></div><div class="status">running...</div></div><div class="output-div"></div></div><ul>
<li><a href="#1-%E5%BC%80%E6%BA%90%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD%E9%87%8F%E6%8E%92%E8%A1%8C%E6%A6%9C2024%E5%B9%B43%E6%9C%88%E6%9B%B4%E6%96%B0%E7%89%88">1 开源大模型下载量排行榜（2024年3月更新版）</a>
<ul>
<li><a href="#%E7%AC%AC%E4%B8%80%E5%90%8Dmistral-7b">第一名：Mistral-7B</a></li>
<li><a href="#%E7%AC%AC%E4%BA%8C%E5%90%8Dllama-2">第二名：LLaMA 2</a></li>
<li><a href="#%E7%AC%AC%E4%B8%89%E5%90%8Dfalcon">第三名：Falcon</a></li>
<li><a href="#%E7%AC%AC%E5%9B%9B%E5%90%8Dgemma">第四名：Gemma</a></li>
<li><a href="#%E7%AC%AC%E4%BA%94%E5%90%8Dchatglm">第五名：ChatGLM</a></li>
<li><a href="#%E7%AC%AC%E5%85%AD%E5%90%8D%E9%80%9A%E4%B9%89%E5%8D%83%E9%97%AE-qwen15">第六名：通义千问 Qwen1.5</a></li>
<li><a href="#%E7%AC%AC%E4%B8%83%E5%90%8Dyi%E7%B3%BB%E5%88%97">第七名：Yi系列</a></li>
<li><a href="#%E7%AC%AC%E5%85%AB%E5%90%8D%E7%99%BE%E5%B7%9D%E5%A4%A7%E6%A8%A1%E5%9E%8B">第八名：百川大模型</a></li>
</ul>
</li>
<li><a href="#%E6%9B%B4%E5%A4%9A%E5%85%B6%E4%BB%96%E6%A8%A1%E5%9E%8B">更多其他模型</a></li>
</ul>
<h1 id="1-开源大模型下载量排行榜2024年3月更新版">1 开源大模型下载量排行榜（2024年3月更新版） </h1>
<p><strong>数据统计时间：</strong><br>
统计日期1：2023.10.12<br>
统计日期2：2024.03.08</p>
<p><strong>排行的标准：</strong><br>
根据 Huggingface 上近一个月的下载量。<br>
模型选择：大厂或者知名Team，基座模型，开源。<br>
魔搭的下载量仅做参考：模型下载量为总下载量，难以反映最近的热度。</p>
<p>下载量作为评价的缺点：</p>
<ul>
<li>宣传的影响：媒体宣传会让模型下载量突然增加。</li>
<li>开发库的影响：知名开发库中设置的默认模型通常下载量比较大。</li>
</ul>
<p><strong>视频解说：</strong><br>
B站：</p>
<iframe width="560" height="315" src="https://player.bilibili.com/player.html?bvid=BV15x42117Za&amp;page=1&amp;autoplay=0" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
<p>油管：</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Ur65L4iAM4o?si=nnbANprNJjFznOVp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
<h2 id="第一名mistral-7b">第一名：Mistral-7B </h2>
<p>小Team，大制作的代表。<br>
十几个人的小Team，制作出了当下最有影响力的LLM。它的7B的模型，性能超好。第一个开源的混合专家模型，用结果进一步证实了对GPT-4的谣传。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>主要区别</td>
<td></td>
<td>第一次统计</td>
</tr>
<tr>
<td>参数量</td>
<td></td>
<td>7B，8x7B</td>
</tr>
<tr>
<td>发布时间</td>
<td></td>
<td>2023年9月（v0.1），12月（v0.2）</td>
</tr>
<tr>
<td>训练数据</td>
<td></td>
<td>不明</td>
</tr>
<tr>
<td>模型类型</td>
<td></td>
<td>Base：Mistral-7B-v0.1，Mixtral-8x7B-v0.1 <br> Chat: Mistral-7B-Instruct-v0.2, Mixtral-8x7B-Instruct-v0.1</td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td></td>
<td>词表：32000，上下文长度：32K以上</td>
</tr>
<tr>
<td>是否商用</td>
<td></td>
<td>不明</td>
</tr>
<tr>
<td>其他</td>
<td></td>
<td>Grouped-Query Attention； Sliding-Window Attention； Byte-fallback BPE tokenizer ；Transformers支持</td>
</tr>
<tr>
<td>技术报告</td>
<td></td>
<td><a href="https://arxiv.org/abs/2310.06825">https://arxiv.org/abs/2310.06825</a></td>
</tr>
<tr>
<td>HF最近月下载量</td>
<td></td>
<td>7B：2590K (超人气) <br> 8x7B: 1255K (超人气)</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">HF合计</th>
<th style="text-align:right">魔搭：Chat版</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">7B</td>
<td style="text-align:right">1425K</td>
<td style="text-align:right">1165K</td>
<td style="text-align:right">2590K</td>
<td style="text-align:right">1.7K</td>
</tr>
<tr>
<td style="text-align:right">8x7B</td>
<td style="text-align:right">187K</td>
<td style="text-align:right">1068K</td>
<td style="text-align:right">1255K</td>
<td style="text-align:right">1786K</td>
</tr>
</tbody>
</table>
<p>相关报道：<br>
<a href="https://mistral.ai/news/la-plateforme/">https://mistral.ai/news/la-plateforme/</a><br>
Github代码库：<br>
<a href="https://github.com/mistralai/mistral-src">https://github.com/mistralai/mistral-src</a></p>
<p>模型下载：<br>
<a href="https://huggingface.co/mistralai/Mistral-7B-v0.1">https://huggingface.co/mistralai/Mistral-7B-v0.1</a><br>
<a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2</a><br>
<a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1">https://huggingface.co/mistralai/Mixtral-8x7B-v0.1</a><br>
<a href="https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1">https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1</a></p>
<h2 id="第二名llama-2">第二名：LLaMA 2 </h2>
<p>Meta于2023年7月发布的最新的开源大模型。是Llama模型的最新版。<br>
最流行，影响力最大的开源模型。目前有很多工作都是基于LLaMA模型的。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>主要区别</td>
<td>第二版</td>
<td>版本无变化</td>
</tr>
<tr>
<td>参数量</td>
<td>7B，13B，70B</td>
<td></td>
</tr>
<tr>
<td>发布时间</td>
<td>2023年7月</td>
<td></td>
</tr>
<tr>
<td>训练时间</td>
<td>2023年1月-7月</td>
<td></td>
</tr>
<tr>
<td>模型类型</td>
<td>Llama2 <br> Llama2-chat （Fine-tuned with SFT and RLHF）</td>
<td></td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td>4k， 词表：32000</td>
<td></td>
</tr>
<tr>
<td>是否商用</td>
<td>商用可（有限制）</td>
<td></td>
</tr>
<tr>
<td>其他</td>
<td>70B model 使用了Grouped-Query Attention <br>（GQA）改善推理</td>
<td>Transformers支持</td>
</tr>
<tr>
<td>技术报告</td>
<td><a href="https://arxiv.org/abs/2307.09288">https://arxiv.org/abs/2307.09288</a></td>
<td></td>
</tr>
<tr>
<td>最近月下载量</td>
<td>7B: 2.4M <br> 13B：15M</td>
<td>7B: 2404K（人气不变） <br> 13B：549K （人气下降）</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Llama2-hf</th>
<th style="text-align:right">Llama2-chat-hf</th>
<th style="text-align:right">合计</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">7B</td>
<td style="text-align:right">1178K</td>
<td style="text-align:right">1226K</td>
<td style="text-align:right">2404K</td>
</tr>
<tr>
<td style="text-align:right">13B</td>
<td style="text-align:right">236K</td>
<td style="text-align:right">313K</td>
<td style="text-align:right">549K</td>
</tr>
<tr>
<td style="text-align:right">70B</td>
<td style="text-align:right">134K</td>
<td style="text-align:right">193K</td>
<td style="text-align:right">327K</td>
</tr>
</tbody>
</table>
<p><strong>HF上链接</strong><br>
<a href="https://huggingface.co/meta-llama/Llama-2-7b-hf">https://huggingface.co/meta-llama/Llama-2-7b-hf</a><br>
<a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf">https://huggingface.co/meta-llama/Llama-2-7b-chat-hf</a><br>
<a href="https://huggingface.co/meta-llama/Llama-2-13b-hf">https://huggingface.co/meta-llama/Llama-2-13b-hf</a><br>
<a href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf">https://huggingface.co/meta-llama/Llama-2-13b-chat-hf</a><br>
<a href="https://huggingface.co/meta-llama/Llama-2-70b-hf">https://huggingface.co/meta-llama/Llama-2-70b-hf</a><br>
<a href="https://huggingface.co/meta-llama/Llama-2-70b-chat-hf">https://huggingface.co/meta-llama/Llama-2-70b-chat-hf</a></p>
<h2 id="第三名falcon">第三名：Falcon </h2>
<p>阿拉伯联合酋长国的研究机构TII公布的基于多语言数据训练的大模型。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>参数量</td>
<td>1B，7B， 40B， 180B</td>
<td></td>
</tr>
<tr>
<td>发布时间</td>
<td>2023年4月~</td>
<td>23.9月: 180B;</td>
</tr>
<tr>
<td>训练数据</td>
<td>350B to 3500B tokens</td>
<td></td>
</tr>
<tr>
<td>模型类型</td>
<td>Base 和 Chat/Instruct</td>
<td></td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td>2k，词表：50304</td>
<td></td>
</tr>
<tr>
<td>是否商用</td>
<td>商用可</td>
<td></td>
</tr>
<tr>
<td>其他</td>
<td>使用 Multi-Query Attention， FlashAttention 技术，PyTorch 2.0</td>
<td>部分训练数据开源；Transformers支持</td>
</tr>
<tr>
<td>技术报告</td>
<td><a href="https://arxiv.org/abs/2306.01116">https://arxiv.org/abs/2306.01116</a></td>
<td></td>
</tr>
<tr>
<td>最近月下载量</td>
<td>7B: 509k <br> 40B：651k</td>
<td>7B: 496K (人气不变) <br> 40B: 952K（人气上涨）</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">HF合计</th>
<th style="text-align:right">魔搭：Chat版</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">RW-1B</td>
<td style="text-align:right">83K</td>
<td style="text-align:right">-</td>
<td style="text-align:right">-</td>
<td style="text-align:right">3k</td>
</tr>
<tr>
<td style="text-align:right">RW-7B</td>
<td style="text-align:right">4.5K</td>
<td style="text-align:right">-</td>
<td style="text-align:right">-</td>
<td style="text-align:right">&lt; 1k</td>
</tr>
<tr>
<td style="text-align:right">7B</td>
<td style="text-align:right">218K</td>
<td style="text-align:right">278K</td>
<td style="text-align:right">496K</td>
<td style="text-align:right">&lt; 1k</td>
</tr>
<tr>
<td style="text-align:right">40B</td>
<td style="text-align:right">45K</td>
<td style="text-align:right">907K</td>
<td style="text-align:right">952K</td>
<td style="text-align:right">&lt; 1k</td>
</tr>
<tr>
<td style="text-align:right">180B</td>
<td style="text-align:right">0.7K</td>
<td style="text-align:right">15K</td>
<td style="text-align:right">15.7K</td>
<td style="text-align:right">&lt; 1k</td>
</tr>
</tbody>
</table>
<p>HF模型：<br>
<a href="https://huggingface.co/tiiuae/falcon-rw-1b%EF%BC%88%E4%BD%BF%E7%94%A8refinedweb%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83%EF%BC%89">https://huggingface.co/tiiuae/falcon-rw-1b（使用refinedweb数据训练）</a><br>
<a href="https://huggingface.co/tiiuae/falcon-rw-7b%EF%BC%88%E4%BD%BF%E7%94%A8refinedweb%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83%EF%BC%89">https://huggingface.co/tiiuae/falcon-rw-7b（使用refinedweb数据训练）</a></p>
<p><a href="https://huggingface.co/tiiuae/falcon-7b">https://huggingface.co/tiiuae/falcon-7b</a><br>
<a href="https://huggingface.co/tiiuae/falcon-7b-chat">https://huggingface.co/tiiuae/falcon-7b-chat</a></p>
<p><a href="https://huggingface.co/tiiuae/falcon-40b-chat">https://huggingface.co/tiiuae/falcon-40b-chat</a><br>
<a href="https://huggingface.co/tiiuae/falcon-180b-chat">https://huggingface.co/tiiuae/falcon-180b-chat</a></p>
<p>开源数据：<br>
<a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb">https://huggingface.co/datasets/tiiuae/falcon-refinedweb</a></p>
<h2 id="第四名gemma">第四名：Gemma </h2>
<p>谷歌第一款开源的LLM，使用了Gemini类似的技术训练。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>主要区别</td>
<td></td>
<td>第一次统计</td>
</tr>
<tr>
<td>参数量</td>
<td></td>
<td>2B，7B</td>
</tr>
<tr>
<td>发布时间</td>
<td></td>
<td>2024年2月</td>
</tr>
<tr>
<td>训练数据</td>
<td></td>
<td>2B：2T；7B：6T</td>
</tr>
<tr>
<td>模型类型</td>
<td></td>
<td>Base，Chat（instruct）</td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td></td>
<td>词表：256000</td>
</tr>
<tr>
<td>是否商用</td>
<td></td>
<td>商用可</td>
</tr>
<tr>
<td>其他</td>
<td></td>
<td>Transformers支持</td>
</tr>
<tr>
<td>技术报告</td>
<td></td>
<td>Gemini: <a href="https://arxiv.org/abs/2312.11805">https://arxiv.org/abs/2312.11805</a></td>
</tr>
<tr>
<td>HF最近月下载量</td>
<td></td>
<td>2B：252K <br> 7B: 366K</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">HF合计</th>
<th style="text-align:right">魔搭：Chat版</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">2B</td>
<td style="text-align:right">121K</td>
<td style="text-align:right">131K</td>
<td style="text-align:right">252K</td>
<td style="text-align:right">1.1K</td>
</tr>
<tr>
<td style="text-align:right">7B</td>
<td style="text-align:right">222K</td>
<td style="text-align:right">144K</td>
<td style="text-align:right">366K</td>
<td style="text-align:right">3.6K</td>
</tr>
</tbody>
</table>
<p>相关报道：<br>
<a href="https://blog.google/technology/developers/gemma-open-models/">https://blog.google/technology/developers/gemma-open-models/</a><br>
<a href="https://huggingface.co/blog/gemma">https://huggingface.co/blog/gemma</a></p>
<p>模型下载：<br>
<a href="https://huggingface.co/google/gemma-2b">https://huggingface.co/google/gemma-2b</a><br>
<a href="https://huggingface.co/google/gemma-2b-it">https://huggingface.co/google/gemma-2b-it</a><br>
<a href="https://huggingface.co/google/gemma-7b">https://huggingface.co/google/gemma-7b</a><br>
<a href="https://huggingface.co/google/gemma-7b-it">https://huggingface.co/google/gemma-7b-it</a></p>
<h2 id="第五名chatglm">第五名：ChatGLM </h2>
<p>ChatGLM 应该是国产第一个开源大模型，最新版为 ChatGLM3-6B。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>参数量</td>
<td>ChatGLM2-6B</td>
<td>ChatGLM3-6B</td>
</tr>
<tr>
<td>发布时间</td>
<td>2023年7月</td>
<td>2023年10月底 ChatGLM3版</td>
</tr>
<tr>
<td>模型类型</td>
<td>Chat （Fine-tuned with ？）</td>
<td></td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td>8k， 32k</td>
<td>8K，32K，128K 窗口版； 词表：65024</td>
</tr>
<tr>
<td>是否商用</td>
<td>商用可，需填写问卷</td>
<td></td>
</tr>
<tr>
<td>其他</td>
<td>基于 Multi-Query Attention 技术的高效推理；<br>基于 FlashAttention 技术拓展上下文长度</td>
<td>源代码没有加入Transformers</td>
</tr>
<tr>
<td>技术报告</td>
<td></td>
<td><a href="https://arxiv.org/abs/2103.10360">https://arxiv.org/abs/2103.10360</a> <br> <a href="https://arxiv.org/abs/2210.02414">https://arxiv.org/abs/2210.02414</a></td>
</tr>
<tr>
<td>最近月下载量</td>
<td>6B:196k</td>
<td>ChatGLM3-6B: 112.5K <br> 魔搭上人气：总下载量达到 924K</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">HF合计</th>
<th style="text-align:right">魔搭：Chat版8K+32K(base版)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">ChatGLM3-6B</td>
<td style="text-align:right">81.4K</td>
<td style="text-align:right">6.9K+14.2K+10K</td>
<td style="text-align:right">112.5K</td>
<td style="text-align:right">81.9K+224K (base:619K)</td>
</tr>
</tbody>
</table>
<p>HF模型：<br>
<a href="https://huggingface.co/THUDM/chatglm3-6b">https://huggingface.co/THUDM/chatglm3-6b</a><br>
<a href="https://huggingface.co/THUDM/chatglm3-6b-base">https://huggingface.co/THUDM/chatglm3-6b-base</a> （Chat版）</p>
<p>Github：<br>
<a href="https://github.com/THUDM/ChatGLM3">https://github.com/THUDM/ChatGLM3</a></p>
<h2 id="第六名通义千问-qwen15">第六名：通义千问 Qwen1.5 </h2>
<p>阿里云公布的大模型，Qwen系列模型，不仅包含文本生成，还衍生出了语音大模型，图形处理的视觉大模型。Qwen1.5版公布了从0.5B到72B的多种尺寸的模型，可以适用于多种需求。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>主要区别</td>
<td>第一版</td>
<td>Qwen1.5 第二版</td>
</tr>
<tr>
<td>参数量</td>
<td>Qwen： 7B， 14B</td>
<td>Qwen1.5： 0.5B, 1.8B, 4B, 7B, 14B, and 72B</td>
</tr>
<tr>
<td>发布时间</td>
<td>2023年8月（7B）9月（14B）</td>
<td>2024年2月</td>
</tr>
<tr>
<td>训练数据</td>
<td>7B（2.2万亿tokens）14B（超过3万亿Token）</td>
<td></td>
</tr>
<tr>
<td>模型类型</td>
<td>Base，Chat（SFT，RLHF），量化版</td>
<td></td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td>原生长度2k, 8k；词表：152064</td>
<td>支持32K上下文</td>
</tr>
<tr>
<td>是否商用</td>
<td>商用可，需要问卷</td>
<td></td>
</tr>
<tr>
<td>其他</td>
<td>开源代码中包含完成的LLM工具（引入了NTK插值、窗口注意力、<br> LogN注意力缩放等技术）</td>
<td>Transformers支持（版本4.37.0，目前中国产LLM中第一个）</td>
</tr>
<tr>
<td>技术报告</td>
<td><a href="https://arxiv.org/abs/2309.16609">https://arxiv.org/abs/2309.16609</a></td>
<td></td>
</tr>
<tr>
<td>HF最近月下载量</td>
<td>7B：26K <br> 14B: 15K</td>
<td>7B：66.5K (人气上升) <br> 14B: 21.8K</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">Chat量化版（合计）</th>
<th style="text-align:right">HG合计</th>
<th style="text-align:right">魔搭：Chat版+4bit</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0.5B</td>
<td style="text-align:right">58.2K</td>
<td style="text-align:right">38.2K</td>
<td style="text-align:right">1.6K</td>
<td style="text-align:right">98.0K</td>
<td style="text-align:right">16.9K</td>
</tr>
<tr>
<td style="text-align:right">1.8B</td>
<td style="text-align:right">15.4K</td>
<td style="text-align:right">19.4K</td>
<td style="text-align:right">1.5K</td>
<td style="text-align:right">36.3K</td>
<td style="text-align:right">5.4k</td>
</tr>
<tr>
<td style="text-align:right">4B</td>
<td style="text-align:right">8.7K</td>
<td style="text-align:right">7.8K</td>
<td style="text-align:right">2.3K</td>
<td style="text-align:right">18.8K</td>
<td style="text-align:right">2.2K</td>
</tr>
<tr>
<td style="text-align:right">7B</td>
<td style="text-align:right">9.0K</td>
<td style="text-align:right">28.1K</td>
<td style="text-align:right">29.5K</td>
<td style="text-align:right">66.5K</td>
<td style="text-align:right">14.3K</td>
</tr>
<tr>
<td style="text-align:right">14B</td>
<td style="text-align:right">6.2K</td>
<td style="text-align:right">12.6K</td>
<td style="text-align:right">3.0K</td>
<td style="text-align:right">21.8K</td>
<td style="text-align:right">6.2K</td>
</tr>
<tr>
<td style="text-align:right">72B</td>
<td style="text-align:right">7.9K</td>
<td style="text-align:right">23.5K</td>
<td style="text-align:right">19.4K</td>
<td style="text-align:right">50.7K</td>
<td style="text-align:right">3.0K</td>
</tr>
</tbody>
</table>
<p><strong>7B模型的各个版本下载链接</strong><br>
<a href="https://huggingface.co/Qwen/Qwen1.5-7B">https://huggingface.co/Qwen/Qwen1.5-7B</a><br>
<a href="https://huggingface.co/Qwen/Qwen1.5-7B-Chat">https://huggingface.co/Qwen/Qwen1.5-7B-Chat</a><br>
<a href="https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GPTQ-Int4">https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GPTQ-Int4</a><br>
<a href="https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GPTQ-Int8">https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GPTQ-Int8</a><br>
<a href="https://huggingface.co/Qwen/Qwen1.5-7B-Chat-AWQ">https://huggingface.co/Qwen/Qwen1.5-7B-Chat-AWQ</a><br>
<a href="https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GGUF">https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GGUF</a></p>
<h2 id="第七名yi系列">第七名：Yi系列 </h2>
<p>零一万物发布的Yi系列模型。李开复老师背书。<br>
此模型发布后，有一些针对它的质疑，比如，伪装为原创架构，也有针对其结果的嫌疑。<br>
具体：<a href="https://www.zhihu.com/question/630152920/answer/3289232318">https://www.zhihu.com/question/630152920/answer/3289232318</a></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>参数量</td>
<td></td>
<td>6B, 9B, 34B</td>
</tr>
<tr>
<td>发布时间</td>
<td></td>
<td>23年11月：6B，34B<br>24年3月：9B，34B-200K</td>
</tr>
<tr>
<td>训练数据</td>
<td></td>
<td>3T，9B模型3.8T</td>
</tr>
<tr>
<td>模型类型</td>
<td></td>
<td>Base, Chat</td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td></td>
<td>4K, 8K，32K，200K 窗口版； 词表：64000</td>
</tr>
<tr>
<td>是否商用</td>
<td></td>
<td>商用可，需要发邮件获取授权</td>
</tr>
<tr>
<td>其他</td>
<td></td>
<td>采用Llama2架构</td>
</tr>
<tr>
<td>技术报告</td>
<td></td>
<td><a href="https://arxiv.org/abs/2403.04652">https://arxiv.org/abs/2403.04652</a></td>
</tr>
<tr>
<td>最近月下载量</td>
<td></td>
<td>6B：34K <br> 34B：36.1K</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">HF合计</th>
<th style="text-align:right">魔搭：Chat版+bit版</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">6B</td>
<td style="text-align:right">17.2K</td>
<td style="text-align:right">16.8K</td>
<td style="text-align:right">34K</td>
<td style="text-align:right">27K</td>
</tr>
<tr>
<td style="text-align:right">9B</td>
<td style="text-align:right">&lt; 1k</td>
<td style="text-align:right">-</td>
<td style="text-align:right">-</td>
<td style="text-align:right">-</td>
</tr>
<tr>
<td style="text-align:right">34B</td>
<td style="text-align:right">10.5K</td>
<td style="text-align:right">25.6K</td>
<td style="text-align:right">36.1K</td>
<td style="text-align:right">21K</td>
</tr>
</tbody>
</table>
<p>统计不包含200K版</p>
<p>HF模型：<br>
<a href="https://huggingface.co/01-ai/Yi-6B">https://huggingface.co/01-ai/Yi-6B</a><br>
<a href="https://huggingface.co/01-ai/Yi-6B-Chat%EF%BC%88Chat%E7%89%88%EF%BC%89">https://huggingface.co/01-ai/Yi-6B-Chat（Chat版）</a></p>
<p>Github：<br>
<a href="https://github.com/01-ai/Yi">https://github.com/01-ai/Yi</a></p>
<h2 id="第八名百川大模型">第八名：百川大模型 </h2>
<p>Baichuan 2 是百川智能推出的新一代开源大语言模型，采用 2.6 万亿 Tokens 的高质量语料训练，在权威的中文和英文 benchmark 上均取得很好的效果。包含有 7B、13B 的 Base 和 Chat 版本。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数据统计1（23年10月）</th>
<th>数据统计2（24年03月）</th>
</tr>
</thead>
<tbody>
<tr>
<td>参数量</td>
<td>7B，13B</td>
<td></td>
</tr>
<tr>
<td>发布时间</td>
<td>2023年9月</td>
<td></td>
</tr>
<tr>
<td>训练时间</td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>模型类型</td>
<td>Base <br> Chat （Fine-tuned with SFT and RLHF）</td>
<td></td>
</tr>
<tr>
<td>上下文Tokens等</td>
<td>4k；词表：125696</td>
<td></td>
</tr>
<tr>
<td>是否商用</td>
<td>商用可，要申请</td>
<td></td>
</tr>
<tr>
<td>其他</td>
<td>需要使用Pytorch2.0</td>
<td></td>
</tr>
<tr>
<td>技术报告</td>
<td><a href="https://arxiv.org/abs/2309.10305">https://arxiv.org/abs/2309.10305</a></td>
<td></td>
</tr>
<tr>
<td>最近月下载量</td>
<td>7B: 49k <br> 13B：263k</td>
<td>7B: 19.1k（人气下降） <br> 13B: 51.9K（人气下降）</td>
</tr>
</tbody>
</table>
<p><strong>人气指数：下载量(Huggingface为最近月下载量，魔搭为总下载量, 统计日期 2024.03.08)</strong></p>
<table>
<thead>
<tr>
<th style="text-align:right">模型</th>
<th style="text-align:right">Base</th>
<th style="text-align:right">Chat</th>
<th style="text-align:right">HF合计</th>
<th style="text-align:right">魔搭：Chat版+4bit</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">7B</td>
<td style="text-align:right">6.4K</td>
<td style="text-align:right">12.7K</td>
<td style="text-align:right">19.1K</td>
<td style="text-align:right">53.6K+34.1k</td>
</tr>
<tr>
<td style="text-align:right">13B</td>
<td style="text-align:right">48.7K</td>
<td style="text-align:right">3.2K</td>
<td style="text-align:right">51.9K</td>
<td style="text-align:right">35.3k+77.5K</td>
</tr>
</tbody>
</table>
<p>详细评价结果：<br>
<a href="https://github.com/baichuan-inc/Baichuan2">https://github.com/baichuan-inc/Baichuan2</a></p>
<p>HF模型：<br>
<a href="https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat">https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat</a></p>
<p>相关报道：<br>
<a href="https://mp.weixin.qq.com/s/TLmnsxFwOadYYVPrFzKoSg">https://mp.weixin.qq.com/s/TLmnsxFwOadYYVPrFzKoSg</a></p>
<h1 id="更多其他模型">更多其他模型 </h1>
<table>
<thead>
<tr>
<th>模型</th>
<th>HF地址</th>
<th style="text-align:right">月下载23.10</th>
<th style="text-align:right">月下载24.03</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vicuna-7B</td>
<td>lmsys/vicuna-7b-v1.5</td>
<td style="text-align:right">136k</td>
<td style="text-align:right">470K</td>
<td>基于LLaMA微调，有开发库</td>
</tr>
<tr>
<td>OPT模型（Meta）</td>
<td>facebook/opt-6.7b</td>
<td style="text-align:right">111k</td>
<td style="text-align:right">119K</td>
<td></td>
</tr>
<tr>
<td>Bloomz模型</td>
<td>bigscience/bloomz-7b1</td>
<td style="text-align:right">68k</td>
<td style="text-align:right">98K</td>
<td></td>
</tr>
<tr>
<td>MPT-7b模型</td>
<td>mosaicml/mpt-7b （mpt-7b-chat）</td>
<td style="text-align:right">123k</td>
<td style="text-align:right">56K</td>
<td></td>
</tr>
<tr>
<td>悟道-天鹰（Aquila2）-7B</td>
<td>BAAI/AquilaChat2-7B</td>
<td style="text-align:right">-</td>
<td style="text-align:right">3K</td>
<td></td>
</tr>
<tr>
<td>Chinese-Alpaca-Plus-7B：</td>
<td>shibing624/chinese-alpaca-plus-7b-hf</td>
<td style="text-align:right">3k</td>
<td style="text-align:right">1K</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td></td>
</tr>
<tr>
<td>Vicuna-13B</td>
<td>lmsys/vicuna-13b-v1.5</td>
<td style="text-align:right">63k</td>
<td style="text-align:right">59K</td>
<td></td>
</tr>
<tr>
<td>Chinese-Alpaca-Plus-13B：</td>
<td>shibing624/chinese-alpaca-plus-13b-hf</td>
<td style="text-align:right">3k</td>
<td style="text-align:right">1K</td>
<td></td>
</tr>
<tr>
<td>悟道-天鹰（Aquila2）-34B</td>
<td>BAAI/AquilaChat2-34B-16K</td>
<td style="text-align:right">-</td>
<td style="text-align:right">5K</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td></td>
</tr>
<tr>
<td>microsoft phi-2</td>
<td>microsoft/phi-2</td>
<td style="text-align:right"></td>
<td style="text-align:right">563K</td>
<td>2.7B参数</td>
</tr>
<tr>
<td>OPT-125M</td>
<td>facebook/opt-125m</td>
<td style="text-align:right"></td>
<td style="text-align:right">695K</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td style="text-align:right"></td>
<td style="text-align:right"></td>
<td></td>
</tr>
<tr>
<td>zephyr</td>
<td>HuggingFaceH4/zephyr-7b-beta</td>
<td style="text-align:right"></td>
<td style="text-align:right">665K</td>
<td></td>
</tr>
</tbody>
</table>
<p>HF模型：<a href="https://huggingface.co/models">https://huggingface.co/models</a><br>
魔搭社区：<a href="https://modelscope.cn/models">https://modelscope.cn/models</a></p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>